{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5a607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\anaconda3\\envs\\cs6140\\Lib\\site-packages\\tslearn\\bases\\bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from metrics import *\n",
    "from utils import utility\n",
    "from tslearn.metrics import SoftDTWLossPyTorch\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dtw import dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc6a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = \"S_norm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d489fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_samples(LABEL, data):\n",
    "    index = {\"F_norm\": [a for a in range(417,712)],\n",
    "             \"N_norm\": [a for a in range(2,1002)],\n",
    "             \"Q_norm\": [a for a in range(46,1133)],\n",
    "             \"S_norm\": [a for a in range(1953, 2721)],\n",
    "             \"V_norm\": [a for a in range(854, 1295)]}\n",
    "    \n",
    "    y = data[index[LABEL]]\n",
    "    # y = y.reshape(y.shape[0], 1, y.shape[-1])\n",
    "    \n",
    "    return y\n",
    "def batching(a, n):\n",
    "    n = min(n, len(a))\n",
    "    k, m = divmod(len(a), n)\n",
    "    \n",
    "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))\n",
    "\n",
    "\n",
    "def loader(label, batch_size, resample):\n",
    "    data = pd.read_pickle(\"../data/\"+label+\".pkl\")\n",
    "    \n",
    "    X = np.array(data[\"beat\"].to_list())\n",
    "    X = signal.resample(X, resample, axis=1)\n",
    "    X = return_samples(label, X)\n",
    "    n = len(X) // batch_size \n",
    "    a = range(n*batch_size)\n",
    "    # n = int(len(data)/batch_size)-1\n",
    "    \n",
    "    batches = list(batching(a, n))\n",
    "    X = torch.Tensor(X)\n",
    "    # X = torch.cat([X, torch.zeros((X.shape[0], 512-X.shape[1]))], dim=1)\n",
    "    \n",
    "    return X, batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e618c5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "data, batches = loader(LABEL, 128, 256)\n",
    "data= data.unsqueeze(1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "208ef25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipeline:\n",
    "    def __init__(self, metric_size):\n",
    "        self.utils = utility()\n",
    "        self.dtw = SoftDTWLossPyTorch(gamma=0.01)\n",
    "        self.metric_size = metric_size\n",
    "        \n",
    "    def process(self, input, samples):\n",
    "        # Convert images once, not repeatedly\n",
    "        input_imgs = self.utils.convert(input.squeeze(1))\n",
    "        sample_imgs = self.utils.convert(samples.squeeze(1))\n",
    "\n",
    "        batch_size, sample_size = input_imgs.shape[0], sample_imgs.shape[0]\n",
    "        \n",
    "        # Pre-allocate metrics tensor\n",
    "        metrics = torch.zeros((batch_size, self.metric_size, sample_size), device=input.device)\n",
    "        \n",
    "        # Vectorize outer loop\n",
    "        for s in range(sample_size):\n",
    "            grayB = sample_imgs[s]  # Shared across batch\n",
    "            # sigB = samples[s].reshape(1, -1, 1)  # Shared across batch\n",
    "            sigB = samples[s]\n",
    "            \n",
    "            # Parallelize batch computation\n",
    "            grayA = input_imgs  # All input images\n",
    "            # sigA = input.reshape(batch_size, -1, 1)  # All input signals\n",
    "            sigA = input\n",
    "            \n",
    "            # Precompute DTW for the entire batch\n",
    "            # dtw_values = torch.stack([self.dtw(sigA[b].reshape(1,-1,1), sigB) for b in range(batch_size)])\n",
    "            tmp = []\n",
    "            for b in range(batch_size):\n",
    "                align = dtw(sigA[b], sigB, dist_method='euclidean')\n",
    "                tmp.append(torch.tensor(align.distance))\n",
    "            dtw_values = torch.stack(tmp)\n",
    "            \n",
    "            # Compute all metrics for the batch\n",
    "            metric_results = torch.stack([torch.tensor([UQI.process(grayA[b], grayB),\n",
    "                                          VIFP.process(grayA[b], grayB),\n",
    "                                          SCC.process(grayA[b], grayB),\n",
    "                                          SAM.process(grayA[b], grayB),\n",
    "                                          ERGAS.process(grayA[b], grayB),\n",
    "                                          RASE.process(grayA[b], grayB),\n",
    "                                          SIFT.process(grayA[b], grayB),\n",
    "                                          SSIM.process(grayA[b], grayB),\n",
    "                                          dtw_values[b]]) for b in range(batch_size)], dim=0)\n",
    "            \n",
    "            metrics[:, :, s] = metric_results\n",
    "\n",
    "        # Take the mean across the sample dimension\n",
    "        # metrics = metrics.mean(dim=2)\n",
    "        return metrics\n",
    "    \n",
    "pip = pipeline(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b583da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REAL DATA TO BE COMPARED WITH\n",
    "REAL = data[np.random.randint(low = 0,high=data.shape[0], size=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea54498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics of Real signals\n",
      "UQI        0.992474\n",
      "VIFP       0.041272\n",
      "SCC        0.001082\n",
      "SAM        0.093675\n",
      "ERGAS      2.347319\n",
      "RASE     187.248143\n",
      "SIFT      32.000000\n",
      "SSIM       0.933158\n",
      "DTW       11.506093\n",
      "dtype: float64\n",
      "UQI       0.990990\n",
      "VIFP      0.004690\n",
      "SCC      -0.007167\n",
      "SAM       0.000000\n",
      "ERGAS     0.000000\n",
      "RASE      0.000000\n",
      "SIFT     16.000000\n",
      "SSIM      0.918791\n",
      "DTW       0.000000\n",
      "dtype: float64\n",
      "UQI        1.000000\n",
      "VIFP       1.000000\n",
      "SCC        0.057839\n",
      "SAM        0.102736\n",
      "ERGAS      2.574510\n",
      "RASE     218.560822\n",
      "SIFT     197.000000\n",
      "SSIM       1.000000\n",
      "DTW       21.518492\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load real and generated Q signals => Real comparison\n",
    "\n",
    "# a = data[np.random.randint(low = 0,high=data.shape[0], size=4)]\n",
    "gen = data[np.random.randint(low = 0,high=data.shape[0], size=16)]\n",
    "\n",
    "\n",
    "# # visualize these signals\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(a.squeeze(1).transpose(0,1))\n",
    "# plt.plot(b.squeeze(1).transpose(0,1))\n",
    "# plt.savefig(\"tmp.png\")\n",
    "\n",
    "# metrics = pip.process(a,b)\n",
    "\n",
    "summ = defaultdict(list)\n",
    "for j in range(4):\n",
    "    # a = data[np.random.randint(low = 0, high = data.shape[0], size = 4)]\n",
    "    b = gen[(j*4):(4 + j*4)]\n",
    "    \n",
    "    metrics = pip.process(REAL,b)\n",
    "    summ[\"UQI\"] += torch.Tensor.tolist(metrics[:,0].reshape(1,-1))[0]\n",
    "    summ[\"VIFP\"] += torch.Tensor.tolist(metrics[:,1].reshape(1,-1))[0]\n",
    "    summ[\"SCC\"] += torch.Tensor.tolist(metrics[:,2].reshape(1,-1))[0]\n",
    "    summ[\"SAM\"] += torch.Tensor.tolist(metrics[:,3].reshape(1,-1))[0]\n",
    "    summ[\"ERGAS\"] += torch.Tensor.tolist(metrics[:,4].reshape(1,-1))[0]\n",
    "    summ[\"RASE\"] += torch.Tensor.tolist(metrics[:,5].reshape(1,-1))[0]\n",
    "    summ[\"SIFT\"] += torch.Tensor.tolist(metrics[:,6].reshape(1,-1))[0]\n",
    "    summ[\"SSIM\"] += torch.Tensor.tolist(metrics[:,7].reshape(1,-1))[0]\n",
    "    summ[\"DTW\"] += torch.Tensor.tolist(metrics[:,8].reshape(1,-1))[0]\n",
    "\n",
    "summ = pd.DataFrame(summ)\n",
    "print(\"Metrics of Real signals\")\n",
    "print(summ.mean())\n",
    "print(summ.min())\n",
    "print(summ.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e00e8546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_47432\\3992016119.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gen = torch.load(\"../Transformer/\"+LABEL[0]+\"_1d.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics of Transformer 1d generated signals\n",
      "UQI        0.991466\n",
      "VIFP       0.027133\n",
      "SCC        0.000172\n",
      "SAM        0.098887\n",
      "ERGAS      2.476627\n",
      "RASE     198.162326\n",
      "SIFT      21.734375\n",
      "SSIM       0.930084\n",
      "DTW       10.942024\n",
      "dtype: float64\n",
      "UQI        0.988922\n",
      "VIFP       0.002722\n",
      "SCC       -0.004153\n",
      "SAM        0.079766\n",
      "ERGAS      1.998655\n",
      "RASE     140.051895\n",
      "SIFT       4.000000\n",
      "SSIM       0.911880\n",
      "DTW        7.011832\n",
      "dtype: float64\n",
      "UQI        0.994453\n",
      "VIFP       0.156498\n",
      "SCC        0.010911\n",
      "SAM        0.110959\n",
      "ERGAS      2.776769\n",
      "RASE     240.216599\n",
      "SIFT      41.000000\n",
      "SSIM       0.954267\n",
      "DTW       19.708237\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load real and generated Q signals => Transformers 1d\n",
    "\n",
    "# a = data[np.random.randint(low = 0,high=data.shape[0], size=4)]\n",
    "gen = torch.load(\"../Transformer/\"+LABEL[0]+\"_1d.pt\")\n",
    "\n",
    "\n",
    "# # visualize these signals\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(a.squeeze(1).transpose(0,1))\n",
    "# plt.plot(b.squeeze(1).transpose(0,1))\n",
    "# plt.savefig(\"tmp.png\")\n",
    "\n",
    "# metrics = pip.process(a,b)\n",
    "\n",
    "summ = defaultdict(list)\n",
    "for j in range(4):\n",
    "    # a = data[np.random.randint(low = 0, high = data.shape[0], size = 4)]\n",
    "    b = gen[(j*4):(4 + j*4)]\n",
    "    \n",
    "    metrics = pip.process(REAL,b)\n",
    "    summ[\"UQI\"] += torch.Tensor.tolist(metrics[:,0].reshape(1,-1))[0]\n",
    "    summ[\"VIFP\"] += torch.Tensor.tolist(metrics[:,1].reshape(1,-1))[0]\n",
    "    summ[\"SCC\"] += torch.Tensor.tolist(metrics[:,2].reshape(1,-1))[0]\n",
    "    summ[\"SAM\"] += torch.Tensor.tolist(metrics[:,3].reshape(1,-1))[0]\n",
    "    summ[\"ERGAS\"] += torch.Tensor.tolist(metrics[:,4].reshape(1,-1))[0]\n",
    "    summ[\"RASE\"] += torch.Tensor.tolist(metrics[:,5].reshape(1,-1))[0]\n",
    "    summ[\"SIFT\"] += torch.Tensor.tolist(metrics[:,6].reshape(1,-1))[0]\n",
    "    summ[\"SSIM\"] += torch.Tensor.tolist(metrics[:,7].reshape(1,-1))[0]\n",
    "    summ[\"DTW\"] += torch.Tensor.tolist(metrics[:,8].reshape(1,-1))[0]\n",
    "\n",
    "summ = pd.DataFrame(summ)\n",
    "print(\"Metrics of Transformer 1d generated signals\")\n",
    "print(summ.mean())\n",
    "print(summ.min())\n",
    "print(summ.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e0561ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_47432\\3568099282.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gen = torch.load(\"../Unet/\"+LABEL[0]+\"_1d.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics of Unet1d generated signals\n",
      "UQI        0.976983\n",
      "VIFP       0.020747\n",
      "SCC       -0.000156\n",
      "SAM        0.140441\n",
      "ERGAS      3.509854\n",
      "RASE     310.643261\n",
      "SIFT      11.468750\n",
      "SSIM       0.910642\n",
      "DTW       33.832653\n",
      "dtype: float64\n",
      "UQI        0.974240\n",
      "VIFP       0.000248\n",
      "SCC       -0.002709\n",
      "SAM        0.125852\n",
      "ERGAS      3.150434\n",
      "RASE     256.767670\n",
      "SIFT       1.000000\n",
      "SSIM       0.899212\n",
      "DTW       21.565685\n",
      "dtype: float64\n",
      "UQI        0.980349\n",
      "VIFP       0.101061\n",
      "SCC        0.005315\n",
      "SAM        0.149260\n",
      "ERGAS      3.728685\n",
      "RASE     343.987671\n",
      "SIFT      25.000000\n",
      "SSIM       0.929541\n",
      "DTW       46.249146\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load real and generated Q signals => Unet 1d\n",
    "\n",
    "# a = data[np.random.randint(low = 0,high=data.shape[0], size=4)]\n",
    "gen = torch.load(\"../Unet/\"+LABEL[0]+\"_1d.pt\")\n",
    "\n",
    "\n",
    "# # visualize these signals\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(a.squeeze(1).transpose(0,1))\n",
    "# plt.plot(b.squeeze(1).transpose(0,1))\n",
    "# plt.savefig(\"tmp.png\")\n",
    "\n",
    "# metrics = pip.process(a,b)\n",
    "\n",
    "summ = defaultdict(list)\n",
    "for j in range(4):\n",
    "    # a = data[np.random.randint(low = 0, high = data.shape[0], size = 4)]\n",
    "    b = gen[(j*4):(4 + j*4)]\n",
    "    \n",
    "    metrics = pip.process(REAL,b)\n",
    "    summ[\"UQI\"] += torch.Tensor.tolist(metrics[:,0].reshape(1,-1))[0]\n",
    "    summ[\"VIFP\"] += torch.Tensor.tolist(metrics[:,1].reshape(1,-1))[0]\n",
    "    summ[\"SCC\"] += torch.Tensor.tolist(metrics[:,2].reshape(1,-1))[0]\n",
    "    summ[\"SAM\"] += torch.Tensor.tolist(metrics[:,3].reshape(1,-1))[0]\n",
    "    summ[\"ERGAS\"] += torch.Tensor.tolist(metrics[:,4].reshape(1,-1))[0]\n",
    "    summ[\"RASE\"] += torch.Tensor.tolist(metrics[:,5].reshape(1,-1))[0]\n",
    "    summ[\"SIFT\"] += torch.Tensor.tolist(metrics[:,6].reshape(1,-1))[0]\n",
    "    summ[\"SSIM\"] += torch.Tensor.tolist(metrics[:,7].reshape(1,-1))[0]\n",
    "    summ[\"DTW\"] += torch.Tensor.tolist(metrics[:,8].reshape(1,-1))[0]\n",
    "\n",
    "summ = pd.DataFrame(summ)\n",
    "print(\"Metrics of Unet1d generated signals\")\n",
    "print(summ.mean())\n",
    "print(summ.min())\n",
    "print(summ.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "316e0e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_47432\\1793344272.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gen = torch.load(\"../UnetAttn/\"+LABEL[0]+\"_1d.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics of Unet1d Attn generated signals\n",
      "UQI        0.983970\n",
      "VIFP       0.014356\n",
      "SCC       -0.000001\n",
      "SAM        0.123602\n",
      "ERGAS      3.090588\n",
      "RASE     261.918316\n",
      "SIFT      16.406250\n",
      "SSIM       0.915315\n",
      "DTW       32.251479\n",
      "dtype: float64\n",
      "UQI        0.982515\n",
      "VIFP       0.002352\n",
      "SCC       -0.003761\n",
      "SAM        0.110693\n",
      "ERGAS      2.768909\n",
      "RASE     217.692535\n",
      "SIFT       4.000000\n",
      "SSIM       0.904588\n",
      "DTW       15.138026\n",
      "dtype: float64\n",
      "UQI        0.986733\n",
      "VIFP       0.077286\n",
      "SCC        0.003091\n",
      "SAM        0.129403\n",
      "ERGAS      3.235091\n",
      "RASE     286.168335\n",
      "SIFT      29.000000\n",
      "SSIM       0.934104\n",
      "DTW       42.551773\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load real and generated Q signals => UnetAttn\n",
    "\n",
    "# a = data[np.random.randint(low = 0,high=data.shape[0], size=4)]\n",
    "gen = torch.load(\"../UnetAttn/\"+LABEL[0]+\"_1d.pt\")\n",
    "\n",
    "# # visualize these signals\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(a.squeeze(1).transpose(0,1))\n",
    "# plt.plot(b.squeeze(1).transpose(0,1))\n",
    "# plt.savefig(\"tmp.png\")\n",
    "\n",
    "# metrics = pip.process(a,b)\n",
    "\n",
    "summ = defaultdict(list)\n",
    "for j in range(4):\n",
    "    # a = data[np.random.randint(low = 0, high = data.shape[0], size = 4)]\n",
    "    b = gen[(j*4):(4 + j*4)]\n",
    "    \n",
    "    metrics = pip.process(REAL,b)\n",
    "    summ[\"UQI\"] += torch.Tensor.tolist(metrics[:,0].reshape(1,-1))[0]\n",
    "    summ[\"VIFP\"] += torch.Tensor.tolist(metrics[:,1].reshape(1,-1))[0]\n",
    "    summ[\"SCC\"] += torch.Tensor.tolist(metrics[:,2].reshape(1,-1))[0]\n",
    "    summ[\"SAM\"] += torch.Tensor.tolist(metrics[:,3].reshape(1,-1))[0]\n",
    "    summ[\"ERGAS\"] += torch.Tensor.tolist(metrics[:,4].reshape(1,-1))[0]\n",
    "    summ[\"RASE\"] += torch.Tensor.tolist(metrics[:,5].reshape(1,-1))[0]\n",
    "    summ[\"SIFT\"] += torch.Tensor.tolist(metrics[:,6].reshape(1,-1))[0]\n",
    "    summ[\"SSIM\"] += torch.Tensor.tolist(metrics[:,7].reshape(1,-1))[0]\n",
    "    summ[\"DTW\"] += torch.Tensor.tolist(metrics[:,8].reshape(1,-1))[0]\n",
    "\n",
    "summ = pd.DataFrame(summ)\n",
    "print(\"Metrics of Unet1d Attn generated signals\")\n",
    "print(summ.mean())\n",
    "print(summ.min())\n",
    "print(summ.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6140",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
